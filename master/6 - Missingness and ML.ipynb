{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvQYUhOqtN0d"
   },
   "source": [
    "# $\\color{purple}{\\text{Understanding Missing Data and How to Deal with It (Part 6)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TopzKHmOtVtL"
   },
   "source": [
    "## $\\color{purple}{\\text{Missing Data in the Age of Machine Learning and Artifical Neural Network}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "colab"
    ]
   },
   "source": [
    "### $\\color{purple}{\\text{Colab Environmental Setup}}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [
     "colab"
    ]
   },
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/My Drive/missingness_tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{purple}{\\text{Libraries for this lesson}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from autoimpute.imputations import MiceImputer\n",
    "from autoimpute.imputations import SingleImputer\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from helpers import ImputationDisplayer, stat_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{purple}{\\text{Neural Network Imputers}}$\n",
    "\n",
    "#### $\\color{purple}{\\text{Denoising Autoencoders}}$\n",
    "\n",
    "* The missing data (or deviation from an imputed value) is treated as noise.\n",
    "* Denoising autoencoders are neural networks trained on the same input and output.\n",
    "* Theory is that the output is trained so that the output is the input with noise removed.\n",
    "* To work properly, data should be normalized during the imputation.\n",
    "\n",
    "`scaler` uses `sklearn`'s `StandardScaler`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/full_set.csv')\n",
    "dmar_df = pd.read_csv('data/double_mar_set.csv')\n",
    "ImputationDisplayer(dmar_df)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dmar_df)\n",
    "sdmar_df = pd.DataFrame(scaler.transform(dmar_df), columns=dmar_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_df(scaler, x):\n",
    "    \"\"\"\n",
    "    Inverse the scaler and created a dataframe\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(scaler.inverse_transform(x), columns = dmar_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic autoencoder proposed by [Gondara and Wang](https://arxiv.org/abs/1705.02737)\n",
    "* Deep neural network with 5 hidden layers with a dropout layer\n",
    "* $\\Theta$ is a hyperparameter governing the expansion and contraction of the layer\n",
    "* $\\Theta=7$ is suggested by best practice.\n",
    "* In the first 3 hidden layers, each layer expands by $\\Theta$ and contracts by $\\Theta$ in the last 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 Impute the data set using univariate imputation\n",
    "The recommendation is that mean or median imputation of numeric data and mode imputation of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_imputed = SingleImputer('median').fit_transform(sdmar_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 Split data into training and test sets\n",
    "This is only necessary if you are building a model that accepts future data (open configuration). If the data set is closed (i.e. you don't expect any new data) then you can set the test_size to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta=7\n",
    "# Divide into training and test sets\n",
    "training, test=train_test_split(univariate_imputed, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 Build, Compile and Train a Deep Neural Network Model\n",
    "* theta and activation function are hyperparameters\n",
    "\n",
    "See `tensorflow` and `keras` documentation for further detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(5+theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+2*theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+3*theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+2*theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',  loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training, training, epochs=50, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the progress of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d3bbad6a0>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 Make Prediction based on initial imputation.\n",
    "We replace the missing values with the predicted value. We also convert back to `pandas` `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(model.predict(univariate_imputed), columns = dmar_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to rescale the data after filling in missing data\n",
    "imputed=restore_df(scaler, sdmar_df.combine_first(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e40b4_row0_col1, #T_e40b4_row1_col0, #T_e40b4_row8_col0 {\n",
       "  background-color: paleturquoise;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e40b4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e40b4_level0_col0\" class=\"col_heading level0 col0\" >feature a</th>\n",
       "      <th id=\"T_e40b4_level0_col1\" class=\"col_heading level0 col1\" >feature b</th>\n",
       "      <th id=\"T_e40b4_level0_col2\" class=\"col_heading level0 col2\" >feature c</th>\n",
       "      <th id=\"T_e40b4_level0_col3\" class=\"col_heading level0 col3\" >feature d</th>\n",
       "      <th id=\"T_e40b4_level0_col4\" class=\"col_heading level0 col4\" >uncorrelated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e40b4_row0_col0\" class=\"data row0 col0\" >2.777245</td>\n",
       "      <td id=\"T_e40b4_row0_col1\" class=\"data row0 col1\" >2.102816</td>\n",
       "      <td id=\"T_e40b4_row0_col2\" class=\"data row0 col2\" >-1.552282</td>\n",
       "      <td id=\"T_e40b4_row0_col3\" class=\"data row0 col3\" >8.772158</td>\n",
       "      <td id=\"T_e40b4_row0_col4\" class=\"data row0 col4\" >0.360789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e40b4_row1_col0\" class=\"data row1 col0\" >2.447336</td>\n",
       "      <td id=\"T_e40b4_row1_col1\" class=\"data row1 col1\" >2.223169</td>\n",
       "      <td id=\"T_e40b4_row1_col2\" class=\"data row1 col2\" >-0.645673</td>\n",
       "      <td id=\"T_e40b4_row1_col3\" class=\"data row1 col3\" >8.815675</td>\n",
       "      <td id=\"T_e40b4_row1_col4\" class=\"data row1 col4\" >0.393466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e40b4_row2_col0\" class=\"data row2 col0\" >1.936893</td>\n",
       "      <td id=\"T_e40b4_row2_col1\" class=\"data row2 col1\" >2.182897</td>\n",
       "      <td id=\"T_e40b4_row2_col2\" class=\"data row2 col2\" >-2.474526</td>\n",
       "      <td id=\"T_e40b4_row2_col3\" class=\"data row2 col3\" >8.549983</td>\n",
       "      <td id=\"T_e40b4_row2_col4\" class=\"data row2 col4\" >0.891191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e40b4_row3_col0\" class=\"data row3 col0\" >2.484183</td>\n",
       "      <td id=\"T_e40b4_row3_col1\" class=\"data row3 col1\" >1.618856</td>\n",
       "      <td id=\"T_e40b4_row3_col2\" class=\"data row3 col2\" >-1.404809</td>\n",
       "      <td id=\"T_e40b4_row3_col3\" class=\"data row3 col3\" >7.360904</td>\n",
       "      <td id=\"T_e40b4_row3_col4\" class=\"data row3 col4\" >0.156937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e40b4_row4_col0\" class=\"data row4 col0\" >2.089727</td>\n",
       "      <td id=\"T_e40b4_row4_col1\" class=\"data row4 col1\" >2.698967</td>\n",
       "      <td id=\"T_e40b4_row4_col2\" class=\"data row4 col2\" >-1.464007</td>\n",
       "      <td id=\"T_e40b4_row4_col3\" class=\"data row4 col3\" >7.786100</td>\n",
       "      <td id=\"T_e40b4_row4_col4\" class=\"data row4 col4\" >0.046178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e40b4_row5_col0\" class=\"data row5 col0\" >3.369940</td>\n",
       "      <td id=\"T_e40b4_row5_col1\" class=\"data row5 col1\" >2.842243</td>\n",
       "      <td id=\"T_e40b4_row5_col2\" class=\"data row5 col2\" >-0.716772</td>\n",
       "      <td id=\"T_e40b4_row5_col3\" class=\"data row5 col3\" >8.767852</td>\n",
       "      <td id=\"T_e40b4_row5_col4\" class=\"data row5 col4\" >0.342830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e40b4_row6_col0\" class=\"data row6 col0\" >0.764542</td>\n",
       "      <td id=\"T_e40b4_row6_col1\" class=\"data row6 col1\" >1.532282</td>\n",
       "      <td id=\"T_e40b4_row6_col2\" class=\"data row6 col2\" >-3.850084</td>\n",
       "      <td id=\"T_e40b4_row6_col3\" class=\"data row6 col3\" >7.992571</td>\n",
       "      <td id=\"T_e40b4_row6_col4\" class=\"data row6 col4\" >0.678203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e40b4_row7_col0\" class=\"data row7 col0\" >3.539507</td>\n",
       "      <td id=\"T_e40b4_row7_col1\" class=\"data row7 col1\" >2.120999</td>\n",
       "      <td id=\"T_e40b4_row7_col2\" class=\"data row7 col2\" >0.181066</td>\n",
       "      <td id=\"T_e40b4_row7_col3\" class=\"data row7 col3\" >7.158813</td>\n",
       "      <td id=\"T_e40b4_row7_col4\" class=\"data row7 col4\" >0.942345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e40b4_row8_col0\" class=\"data row8 col0\" >2.312462</td>\n",
       "      <td id=\"T_e40b4_row8_col1\" class=\"data row8 col1\" >1.816557</td>\n",
       "      <td id=\"T_e40b4_row8_col2\" class=\"data row8 col2\" >-1.325628</td>\n",
       "      <td id=\"T_e40b4_row8_col3\" class=\"data row8 col3\" >8.144401</td>\n",
       "      <td id=\"T_e40b4_row8_col4\" class=\"data row8 col4\" >0.460626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e40b4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e40b4_row9_col0\" class=\"data row9 col0\" >0.445575</td>\n",
       "      <td id=\"T_e40b4_row9_col1\" class=\"data row9 col1\" >0.827475</td>\n",
       "      <td id=\"T_e40b4_row9_col2\" class=\"data row9 col2\" >-4.705004</td>\n",
       "      <td id=\"T_e40b4_row9_col3\" class=\"data row9 col3\" >8.161819</td>\n",
       "      <td id=\"T_e40b4_row9_col4\" class=\"data row9 col4\" >0.014623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6d3bd6ffd0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmar_df.displayer(imputed, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>With Missing Data</th>\n",
       "      <th>difference</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.411082</td>\n",
       "      <td>2.222218</td>\n",
       "      <td>0.188864</td>\n",
       "      <td>7.833155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>2.420924</td>\n",
       "      <td>2.323133</td>\n",
       "      <td>0.097791</td>\n",
       "      <td>4.039402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev</th>\n",
       "      <td>1.279456</td>\n",
       "      <td>1.132181</td>\n",
       "      <td>0.147275</td>\n",
       "      <td>11.510744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original  With Missing Data  difference  percentage\n",
       "mean    2.411082           2.222218    0.188864    7.833155\n",
       "median  2.420924           2.323133    0.097791    4.039402\n",
       "stdev   1.279456           1.132181    0.147275   11.510744"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_comparison(df, imputed, 'feature a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>With Missing Data</th>\n",
       "      <th>difference</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.167609</td>\n",
       "      <td>2.061645</td>\n",
       "      <td>0.105964</td>\n",
       "      <td>4.888531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>2.169837</td>\n",
       "      <td>2.090655</td>\n",
       "      <td>0.079183</td>\n",
       "      <td>3.649238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev</th>\n",
       "      <td>0.752618</td>\n",
       "      <td>0.668361</td>\n",
       "      <td>0.084257</td>\n",
       "      <td>11.195223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original  With Missing Data  difference  percentage\n",
       "mean    2.167609           2.061645    0.105964    4.888531\n",
       "median  2.169837           2.090655    0.079183    3.649238\n",
       "stdev   0.752618           0.668361    0.084257   11.195223"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_comparison(df, imputed, 'feature b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\color{purple}{\\text{Improved Feedback Denoising Autoencoders}}$\n",
    "\n",
    "My own enhancement to the denoising autoencoder see [here](https://arxiv.org/abs/2002.08338)\n",
    "\n",
    "The algorithm was designed for closed data sets. This example shows one enhancement to the denoising autoencoder (DAE), the iterative refinement of the imputed values. It starts similarly by univariate imputation as **step 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_imputation = SingleImputer('median').fit_transform(sdmar_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 Build and Compile Deep Neural Network Model\n",
    "We use the same architecture as the DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(5+theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+2*theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+3*theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+2*theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5+theta, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 Initial Fit\n",
    "Fewer epochs than standard DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [model.fit(univariate_imputation, univariate_imputation, epochs=10,verbose=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(model.predict(univariate_imputation), columns = dmar_df.columns)\n",
    "iterated_imputation=sdmar_df.combine_first(predicted)\n",
    "history.append(model.fit(iterated_imputation, iterated_imputation, epochs=2, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the Iteration a Prescribed Number of Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(0, 19):\n",
    "    predicted = pd.DataFrame(model.predict(iterated_imputation), columns = dmar_df.columns)\n",
    "    iterated_imputation=sdmar_df.combine_first(predicted)\n",
    "    history.append(model.fit(iterated_imputation, iterated_imputation, epochs=2, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d889a7e20>]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since we collected history in several batches, concatenate them so we can see a plot\n",
    "losses = sum([each.history['loss'] for each in history],[])\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plug the final prediction into the missing values and rescale the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(model.predict(iterated_imputation), columns = dmar_df.columns)\n",
    "imputed=restore_df(scaler, sdmar_df.combine_first(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a2c14_row0_col1, #T_a2c14_row1_col0, #T_a2c14_row8_col0 {\n",
       "  background-color: paleturquoise;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a2c14\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a2c14_level0_col0\" class=\"col_heading level0 col0\" >feature a</th>\n",
       "      <th id=\"T_a2c14_level0_col1\" class=\"col_heading level0 col1\" >feature b</th>\n",
       "      <th id=\"T_a2c14_level0_col2\" class=\"col_heading level0 col2\" >feature c</th>\n",
       "      <th id=\"T_a2c14_level0_col3\" class=\"col_heading level0 col3\" >feature d</th>\n",
       "      <th id=\"T_a2c14_level0_col4\" class=\"col_heading level0 col4\" >uncorrelated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a2c14_row0_col0\" class=\"data row0 col0\" >2.777245</td>\n",
       "      <td id=\"T_a2c14_row0_col1\" class=\"data row0 col1\" >2.229025</td>\n",
       "      <td id=\"T_a2c14_row0_col2\" class=\"data row0 col2\" >-1.552282</td>\n",
       "      <td id=\"T_a2c14_row0_col3\" class=\"data row0 col3\" >8.772158</td>\n",
       "      <td id=\"T_a2c14_row0_col4\" class=\"data row0 col4\" >0.360789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a2c14_row1_col0\" class=\"data row1 col0\" >2.717194</td>\n",
       "      <td id=\"T_a2c14_row1_col1\" class=\"data row1 col1\" >2.223169</td>\n",
       "      <td id=\"T_a2c14_row1_col2\" class=\"data row1 col2\" >-0.645673</td>\n",
       "      <td id=\"T_a2c14_row1_col3\" class=\"data row1 col3\" >8.815675</td>\n",
       "      <td id=\"T_a2c14_row1_col4\" class=\"data row1 col4\" >0.393466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a2c14_row2_col0\" class=\"data row2 col0\" >1.936893</td>\n",
       "      <td id=\"T_a2c14_row2_col1\" class=\"data row2 col1\" >2.182897</td>\n",
       "      <td id=\"T_a2c14_row2_col2\" class=\"data row2 col2\" >-2.474526</td>\n",
       "      <td id=\"T_a2c14_row2_col3\" class=\"data row2 col3\" >8.549983</td>\n",
       "      <td id=\"T_a2c14_row2_col4\" class=\"data row2 col4\" >0.891191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a2c14_row3_col0\" class=\"data row3 col0\" >2.484183</td>\n",
       "      <td id=\"T_a2c14_row3_col1\" class=\"data row3 col1\" >1.618856</td>\n",
       "      <td id=\"T_a2c14_row3_col2\" class=\"data row3 col2\" >-1.404809</td>\n",
       "      <td id=\"T_a2c14_row3_col3\" class=\"data row3 col3\" >7.360904</td>\n",
       "      <td id=\"T_a2c14_row3_col4\" class=\"data row3 col4\" >0.156937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a2c14_row4_col0\" class=\"data row4 col0\" >2.089727</td>\n",
       "      <td id=\"T_a2c14_row4_col1\" class=\"data row4 col1\" >2.698967</td>\n",
       "      <td id=\"T_a2c14_row4_col2\" class=\"data row4 col2\" >-1.464007</td>\n",
       "      <td id=\"T_a2c14_row4_col3\" class=\"data row4 col3\" >7.786100</td>\n",
       "      <td id=\"T_a2c14_row4_col4\" class=\"data row4 col4\" >0.046178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a2c14_row5_col0\" class=\"data row5 col0\" >3.369940</td>\n",
       "      <td id=\"T_a2c14_row5_col1\" class=\"data row5 col1\" >2.842243</td>\n",
       "      <td id=\"T_a2c14_row5_col2\" class=\"data row5 col2\" >-0.716772</td>\n",
       "      <td id=\"T_a2c14_row5_col3\" class=\"data row5 col3\" >8.767852</td>\n",
       "      <td id=\"T_a2c14_row5_col4\" class=\"data row5 col4\" >0.342830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a2c14_row6_col0\" class=\"data row6 col0\" >0.764542</td>\n",
       "      <td id=\"T_a2c14_row6_col1\" class=\"data row6 col1\" >1.532282</td>\n",
       "      <td id=\"T_a2c14_row6_col2\" class=\"data row6 col2\" >-3.850084</td>\n",
       "      <td id=\"T_a2c14_row6_col3\" class=\"data row6 col3\" >7.992571</td>\n",
       "      <td id=\"T_a2c14_row6_col4\" class=\"data row6 col4\" >0.678203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a2c14_row7_col0\" class=\"data row7 col0\" >3.539507</td>\n",
       "      <td id=\"T_a2c14_row7_col1\" class=\"data row7 col1\" >2.120999</td>\n",
       "      <td id=\"T_a2c14_row7_col2\" class=\"data row7 col2\" >0.181066</td>\n",
       "      <td id=\"T_a2c14_row7_col3\" class=\"data row7 col3\" >7.158813</td>\n",
       "      <td id=\"T_a2c14_row7_col4\" class=\"data row7 col4\" >0.942345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a2c14_row8_col0\" class=\"data row8 col0\" >2.737183</td>\n",
       "      <td id=\"T_a2c14_row8_col1\" class=\"data row8 col1\" >1.816557</td>\n",
       "      <td id=\"T_a2c14_row8_col2\" class=\"data row8 col2\" >-1.325628</td>\n",
       "      <td id=\"T_a2c14_row8_col3\" class=\"data row8 col3\" >8.144401</td>\n",
       "      <td id=\"T_a2c14_row8_col4\" class=\"data row8 col4\" >0.460626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2c14_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a2c14_row9_col0\" class=\"data row9 col0\" >0.445575</td>\n",
       "      <td id=\"T_a2c14_row9_col1\" class=\"data row9 col1\" >0.827475</td>\n",
       "      <td id=\"T_a2c14_row9_col2\" class=\"data row9 col2\" >-4.705004</td>\n",
       "      <td id=\"T_a2c14_row9_col3\" class=\"data row9 col3\" >8.161819</td>\n",
       "      <td id=\"T_a2c14_row9_col4\" class=\"data row9 col4\" >0.014623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6d883f8700>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmar_df.displayer(imputed, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>With Missing Data</th>\n",
       "      <th>difference</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.411082</td>\n",
       "      <td>2.277080</td>\n",
       "      <td>0.134003</td>\n",
       "      <td>5.557778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>2.420924</td>\n",
       "      <td>2.441958</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>0.868836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev</th>\n",
       "      <td>1.279456</td>\n",
       "      <td>1.150020</td>\n",
       "      <td>0.129436</td>\n",
       "      <td>10.116457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original  With Missing Data  difference  percentage\n",
       "mean    2.411082           2.277080    0.134003    5.557778\n",
       "median  2.420924           2.441958    0.021034    0.868836\n",
       "stdev   1.279456           1.150020    0.129436   10.116457"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_comparison(df, imputed, 'feature a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILSdXRpPtiU8"
   },
   "source": [
    "## $\\color{purple}{\\text{How Imputation Fits Into Your Machine Learning Models}}$\n",
    "\n",
    "* Typical ML Workflow\n",
    "  * Train\n",
    "  * Test\n",
    "  * Use\n",
    "* Save Your Pipeline\n",
    "* You can include an imputer in your pipeline\n",
    "\n",
    "* We demonstrate this using `sklearn`'s pipeline. But this is meant to describe abstractly what you should do\n",
    "\n",
    "Same data set is taken from the [Wine Quality Dataset at UCI](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)\n",
    "\n",
    "This demonstrates a typical pipeline. The final column `quality` is the predicted value. The `features` variable contains all the other column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "0AcjuKGBZBDN"
   },
   "outputs": [],
   "source": [
    "training=pd.read_csv('data/original_wine_training.csv')\n",
    "test=pd.read_csv('data/original_wine_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.082</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.99850</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.7</td>\n",
       "      <td>red</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.052</td>\n",
       "      <td>55.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.9</td>\n",
       "      <td>white</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.123</td>\n",
       "      <td>27.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.4</td>\n",
       "      <td>white</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.37</td>\n",
       "      <td>16.95</td>\n",
       "      <td>0.048</td>\n",
       "      <td>43.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.99950</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.2</td>\n",
       "      <td>white</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.028</td>\n",
       "      <td>32.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.1</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.062</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>11.5</td>\n",
       "      <td>red</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.070</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>11.0</td>\n",
       "      <td>red</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.036</td>\n",
       "      <td>35.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.98936</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.44</td>\n",
       "      <td>13.5</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.27</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>46.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.2</td>\n",
       "      <td>white</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.039</td>\n",
       "      <td>36.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.99059</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.1</td>\n",
       "      <td>white</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               8.0             0.500         0.39            2.60      0.082   \n",
       "1               6.6             0.280         0.28            8.50      0.052   \n",
       "2               7.0             0.190         0.23            5.70      0.123   \n",
       "3               7.4             0.200         0.37           16.95      0.048   \n",
       "4               7.8             0.280         0.34            1.60      0.028   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4995            9.8             0.300         0.39            1.70      0.062   \n",
       "4996            8.3             0.845         0.01            2.20      0.070   \n",
       "4997            7.1             0.360         0.28            2.40      0.036   \n",
       "4998            6.6             0.240         0.27           15.80      0.035   \n",
       "4999            6.9             0.300         0.45            1.40      0.039   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    12.0                  46.0  0.99850  3.43       0.62   \n",
       "1                    55.0                 211.0  0.99620  3.09       0.55   \n",
       "2                    27.0                 104.0  0.99540  3.04       0.54   \n",
       "3                    43.0                 190.0  0.99950  3.03       0.42   \n",
       "4                    32.0                 118.0  0.99010  3.00       0.38   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4995                  3.0                   9.0  0.99480  3.14       0.57   \n",
       "4996                  5.0                  14.0  0.99670  3.32       0.58   \n",
       "4997                 35.0                 115.0  0.98936  3.19       0.44   \n",
       "4998                 46.0                 188.0  0.99820  3.24       0.51   \n",
       "4999                 36.0                 122.0  0.99059  3.07       0.47   \n",
       "\n",
       "      alcohol   type  quality  \n",
       "0        10.7    red        6  \n",
       "1         8.9  white        6  \n",
       "2         9.4  white        6  \n",
       "3         9.2  white        6  \n",
       "4        12.1  white        7  \n",
       "...       ...    ...      ...  \n",
       "4995     11.5    red        7  \n",
       "4996     11.0    red        4  \n",
       "4997     13.5  white        7  \n",
       "4998      9.2  white        5  \n",
       "4999     11.1  white        7  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(training.columns[0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the pipeline by one-hot encoding the `type` column which is categorical, then scale it, then apply random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "        ColumnTransformer([(\"type\", OneHotEncoder(),[\"type\"])],remainder='passthrough'),\n",
    "    StandardScaler(), RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('type', OneHotEncoder(),\n",
       "                                                  ['type'])])),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(training[features], training['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5432417180317055"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test[features], test['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.89, 5.49, 5.93, ..., 6.91, 5.16, 6.75])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(training[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZZt4mf7mpd6"
   },
   "source": [
    "### Imputer in the Pipeline\n",
    "\n",
    "This is meant to demonstrate workflow and `autoimpute` is used as an example.\n",
    "\n",
    "One drawback is that `autoimpute` imputers require a `pandas` `DataFrame` as an input so custom transformers need to be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_hack = FunctionTransformer(lambda x: pd.DataFrame(x, columns = ['type_r', 'type_w']+features[0:-1]))\n",
    "pandas_hack_full = FunctionTransformer(lambda x: pd.DataFrame(x, columns = ['type_r', 'type_w']+features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert the imputer into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(ColumnTransformer([\n",
    "   (\"type\", OneHotEncoder(),['type'])],remainder='passthrough'), pandas_hack, SingleImputer(strategy='least squares'),\n",
    "                         StandardScaler(), RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('type', OneHotEncoder(),\n",
       "                                                  ['type'])])),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('functiontransformer',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x7f6d89265e50>)),\n",
       "                ('miceimputer', MiceImputer(k=5, strategy='stochastic'))])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_training=pd.read_csv('data/wine_training.csv')\n",
    "pipeline.fit(wine_missing[features], wine_training['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MiceImputer' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [319]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m wine_test\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/wine_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m(wine_test[features], wine_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/metaestimators.py:109\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    103\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py:45\u001b[0m, in \u001b[0;36m_final_estimator_has.<locals>.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MiceImputer' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "wine_test=pd.read_csv('data/wine_test.csv')\n",
    "pipeline.score(wine_test[features], wine_test['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MiceImputer' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [320]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m wine_future\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/wine_future.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(wine_future[features]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/metaestimators.py:109\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    103\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py:45\u001b[0m, in \u001b[0;36m_final_estimator_has.<locals>.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MiceImputer' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "wine_future=pd.read_csv('data/wine_future.csv')\n",
    "pipeline.predict(wine_future[features].iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLFveTJtmvzZ"
   },
   "source": [
    "Neural Network Based Autoencoder Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Multiple Imputation fit in?\n",
    "\n",
    "### Approach 1: Augment Data with Multiple Copies\n",
    "\n",
    "Augmentation teachs the model that the imputed values are \"fuzzy\" by providing different values.\n",
    "\n",
    "We create the same pipeline except we have a MiceImputer at the end.\n",
    "The resultant `dfs` are 5 copies of our dataframe with 5 separate imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2640,
     "status": "ok",
     "timestamp": 1654712480068,
     "user": {
      "displayName": "Haw-minn Lu",
      "userId": "16109571175851064283"
     },
     "user_tz": 420
    },
    "id": "zwFrIcTcm87_",
    "outputId": "bf99ee06-2531-437c-988b-c1bd2d87652e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(ColumnTransformer([\n",
    "   (\"type\", OneHotEncoder(),['type'])],remainder='passthrough'),\n",
    "                         StandardScaler(),pandas_hack, MiceImputer(k=5, strategy='stochastic'))\n",
    "dfs = [each[1] for each in pipeline.fit_transform(wine_training[features])]\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdHaAdHHm38b"
   },
   "source": [
    "We augment the training set by concatenating the 5 different data frame. Equivalently, we could rotate each epoch with different imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_training = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsfJcQLfm9rh"
   },
   "source": [
    "Build out model as a classification problem. Bear in mind this is just for demonstration purposes, we model is not a particularly good estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)]\n",
    ")\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = pd.concat([wine_training.quality,\n",
    "                     wine_training.quality,\n",
    "                     wine_training.quality,\n",
    "                     wine_training.quality,\n",
    "                     wine_training.quality])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "id": "e8ZUY3sEjJax"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ce2528f70>"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(augmented_training, quality, epochs=10, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since test set is used to evaluate when the model may hit overtraining, it is not necessary to multiply impute the tests. But you may."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs = [each[1] for each in pipeline.transform(wine_test[features])]\n",
    "test1 = test_dfs[0] # Variation one, just take one imputation\n",
    "test2 = pd.concat(test_dfs) # Variation two augment in the same way\n",
    "quality1 = wine_test.quality\n",
    "quality2 = pd.concat([quality1, quality1, quality1, quality1, quality1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0336 - accuracy: 0.5420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0335584878921509, 0.5419999957084656]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test1, quality1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "tags": [
     "master"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 1.0395 - accuracy: 0.5394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0394865274429321, 0.5393999814987183]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test2, quality2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about future values?\n",
    "Same options:\n",
    " * take one imputation\n",
    " * run all imputations through the model and us an ensemble technique to combine (e.g., majority voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dfs = [each[1].iloc[[0]] for each in pipeline.transform(wine_future[features])]\n",
    "future1 = future_dfs[0] # Variation one, just take one imputation\n",
    "future2 = pd.concat(future_dfs) # Variation two augment in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variation 1: Pick First Imputed\n",
    "np.argmax(model.predict(future1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variation 2: Aggregate all Imputed\n",
    "np.argmax(model.predict(future2).sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Combine Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)]\n",
    ") for _ in range(0,5)]\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model is trained on a different imputation model. Each model should be tested under each imputation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, training in zip(models, dfs):\n",
    "    model.fit(training, wine_training.quality, epochs=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0722581148147583, 0.5299999713897705]\n",
      "[1.072456955909729, 0.5320000052452087]\n",
      "[1.0794332027435303, 0.5199999809265137]\n",
      "[1.0710456371307373, 0.5320000052452087]\n",
      "[1.0745283365249634, 0.5189999938011169]\n"
     ]
    }
   ],
   "source": [
    "for model, test in zip(models, test_dfs):\n",
    "    print (model.evaluate(test, wine_test.quality, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np vstack turns the list of arrays into an array of arrays\n",
    "predictions = np.vstack([model.predict(future) for model, future in zip(models, future_dfs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate predictions\n",
    "np.argmax(predictions.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worth Mentioning: Use Single Imputation with Bagging\n",
    "\n",
    "Short for bootstrap and aggregation\n",
    "\n",
    "Rather than multiple imputation, single imputations are performed from resampled datasets (bootstrapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(ColumnTransformer([\n",
    "   (\"type\", OneHotEncoder(),['type'])],remainder='passthrough'),\n",
    "                         StandardScaler(),pandas_hack_full, MiceImputer(k=1, strategy='stochastic'))\n",
    "bagged_dfs = [next(pipeline.fit_transform(wine_training.sample(frac=1, replace=True)))[1] for _ in range(0,5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(20, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)]\n",
    ") for _ in range(0,5)]\n",
    "for model in models:\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, training in zip(models, dfs):\n",
    "    model.fit(training, wine_training.quality, epochs=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.vstack([model.predict(future) for model, future in zip(models, future_dfs)])\n",
    "# Aggregate predictions\n",
    "np.argmax(predictions.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worth Mentioning: Use missingness as a feature\n",
    "\n",
    "The idea is that you are giving information to the model as to which values are imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(ColumnTransformer([\n",
    "   (\"type\", OneHotEncoder(),['type'])],remainder='passthrough'),\n",
    "                         StandardScaler(),pandas_hack, SingleImputer(strategy='stochastic'))\n",
    "processed=pipeline.fit_transform(wine_test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a feature for each feature that has missing values indicating whether the corresponding row entry is missing that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in features:\n",
    "    processed[f'{each}_missing']=wine_test[each].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_r</th>\n",
       "      <th>type_w</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>...</th>\n",
       "      <th>citric acid_missing</th>\n",
       "      <th>residual sugar_missing</th>\n",
       "      <th>chlorides_missing</th>\n",
       "      <th>free sulfur dioxide_missing</th>\n",
       "      <th>total sulfur dioxide_missing</th>\n",
       "      <th>density_missing</th>\n",
       "      <th>pH_missing</th>\n",
       "      <th>sulphates_missing</th>\n",
       "      <th>alcohol_missing</th>\n",
       "      <th>type_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.718304</td>\n",
       "      <td>-1.718304</td>\n",
       "      <td>0.663555</td>\n",
       "      <td>1.448871</td>\n",
       "      <td>-0.583833</td>\n",
       "      <td>-0.836745</td>\n",
       "      <td>0.806965</td>\n",
       "      <td>-0.307492</td>\n",
       "      <td>-0.190794</td>\n",
       "      <td>0.505750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>-0.867392</td>\n",
       "      <td>0.549951</td>\n",
       "      <td>-1.876388</td>\n",
       "      <td>-0.811454</td>\n",
       "      <td>-0.619186</td>\n",
       "      <td>0.348643</td>\n",
       "      <td>0.142705</td>\n",
       "      <td>-1.665259</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>0.905283</td>\n",
       "      <td>-0.860624</td>\n",
       "      <td>2.978233</td>\n",
       "      <td>-0.172977</td>\n",
       "      <td>-0.359886</td>\n",
       "      <td>-0.443001</td>\n",
       "      <td>0.707848</td>\n",
       "      <td>-0.773533</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>1.388740</td>\n",
       "      <td>-0.456462</td>\n",
       "      <td>0.238182</td>\n",
       "      <td>1.179730</td>\n",
       "      <td>-0.846074</td>\n",
       "      <td>-0.585088</td>\n",
       "      <td>0.879915</td>\n",
       "      <td>0.697814</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>-0.464511</td>\n",
       "      <td>-1.033836</td>\n",
       "      <td>-0.035823</td>\n",
       "      <td>-0.898027</td>\n",
       "      <td>-0.068124</td>\n",
       "      <td>-0.913156</td>\n",
       "      <td>-0.752478</td>\n",
       "      <td>-1.270842</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>-0.706239</td>\n",
       "      <td>-1.033836</td>\n",
       "      <td>0.101179</td>\n",
       "      <td>-0.227085</td>\n",
       "      <td>-0.489536</td>\n",
       "      <td>0.298171</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>-0.972457</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>-0.037249</td>\n",
       "      <td>-0.283250</td>\n",
       "      <td>0.786192</td>\n",
       "      <td>-0.501291</td>\n",
       "      <td>-0.327473</td>\n",
       "      <td>0.701946</td>\n",
       "      <td>1.704888</td>\n",
       "      <td>-0.041400</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>-0.786816</td>\n",
       "      <td>-0.860624</td>\n",
       "      <td>0.169681</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>-0.878487</td>\n",
       "      <td>-0.509380</td>\n",
       "      <td>-0.717373</td>\n",
       "      <td>-1.555508</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.718304</td>\n",
       "      <td>-1.718304</td>\n",
       "      <td>-1.431425</td>\n",
       "      <td>0.409598</td>\n",
       "      <td>-0.241327</td>\n",
       "      <td>-0.703237</td>\n",
       "      <td>-0.593481</td>\n",
       "      <td>-0.408436</td>\n",
       "      <td>-1.324124</td>\n",
       "      <td>0.018731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.581969</td>\n",
       "      <td>0.581969</td>\n",
       "      <td>0.180098</td>\n",
       "      <td>0.063174</td>\n",
       "      <td>-0.515332</td>\n",
       "      <td>-0.724881</td>\n",
       "      <td>-1.235025</td>\n",
       "      <td>-0.004661</td>\n",
       "      <td>-0.822689</td>\n",
       "      <td>-1.871042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type_r    type_w  fixed acidity  volatile acidity  citric acid  \\\n",
       "0    1.718304 -1.718304       0.663555          1.448871    -0.583833   \n",
       "1   -0.581969  0.581969      -0.867392          0.549951    -1.876388   \n",
       "2   -0.581969  0.581969       0.905283         -0.860624     2.978233   \n",
       "3   -0.581969  0.581969       1.388740         -0.456462     0.238182   \n",
       "4   -0.581969  0.581969      -0.464511         -1.033836    -0.035823   \n",
       "..        ...       ...            ...               ...          ...   \n",
       "995 -0.581969  0.581969      -0.706239         -1.033836     0.101179   \n",
       "996 -0.581969  0.581969      -0.037249         -0.283250     0.786192   \n",
       "997 -0.581969  0.581969      -0.786816         -0.860624     0.169681   \n",
       "998  1.718304 -1.718304      -1.431425          0.409598    -0.241327   \n",
       "999 -0.581969  0.581969       0.180098          0.063174    -0.515332   \n",
       "\n",
       "     residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "0         -0.836745   0.806965            -0.307492             -0.190794   \n",
       "1         -0.811454  -0.619186             0.348643              0.142705   \n",
       "2         -0.172977  -0.359886            -0.443001              0.707848   \n",
       "3          1.179730  -0.846074            -0.585088              0.879915   \n",
       "4         -0.898027  -0.068124            -0.913156             -0.752478   \n",
       "..              ...        ...                  ...                   ...   \n",
       "995       -0.227085  -0.489536             0.298171              0.019837   \n",
       "996       -0.501291  -0.327473             0.701946              1.704888   \n",
       "997        0.032635  -0.878487            -0.509380             -0.717373   \n",
       "998       -0.703237  -0.593481            -0.408436             -1.324124   \n",
       "999       -0.724881  -1.235025            -0.004661             -0.822689   \n",
       "\n",
       "      density  ...  citric acid_missing  residual sugar_missing  \\\n",
       "0    0.505750  ...                    0                       1   \n",
       "1   -1.665259  ...                    1                       0   \n",
       "2   -0.773533  ...                    0                       0   \n",
       "3    0.697814  ...                    0                       0   \n",
       "4   -1.270842  ...                    0                       0   \n",
       "..        ...  ...                  ...                     ...   \n",
       "995 -0.972457  ...                    0                       0   \n",
       "996 -0.041400  ...                    0                       1   \n",
       "997 -1.555508  ...                    0                       0   \n",
       "998  0.018731  ...                    0                       0   \n",
       "999 -1.871042  ...                    0                       0   \n",
       "\n",
       "     chlorides_missing  free sulfur dioxide_missing  \\\n",
       "0                    0                            0   \n",
       "1                    0                            0   \n",
       "2                    0                            1   \n",
       "3                    0                            0   \n",
       "4                    1                            0   \n",
       "..                 ...                          ...   \n",
       "995                  0                            0   \n",
       "996                  0                            0   \n",
       "997                  0                            0   \n",
       "998                  1                            0   \n",
       "999                  0                            0   \n",
       "\n",
       "     total sulfur dioxide_missing  density_missing  pH_missing  \\\n",
       "0                               0                0           0   \n",
       "1                               0                0           0   \n",
       "2                               1                0           0   \n",
       "3                               0                0           0   \n",
       "4                               0                0           0   \n",
       "..                            ...              ...         ...   \n",
       "995                             0                0           0   \n",
       "996                             0                1           0   \n",
       "997                             0                0           0   \n",
       "998                             1                0           0   \n",
       "999                             0                0           0   \n",
       "\n",
       "     sulphates_missing  alcohol_missing  type_missing  \n",
       "0                    0                0             0  \n",
       "1                    0                0             0  \n",
       "2                    0                0             0  \n",
       "3                    0                0             0  \n",
       "4                    0                0             0  \n",
       "..                 ...              ...           ...  \n",
       "995                  0                0             0  \n",
       "996                  0                0             0  \n",
       "997                  0                0             0  \n",
       "998                  0                1             0  \n",
       "999                  0                0             0  \n",
       "\n",
       "[1000 rows x 25 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* The bulk of work with models dealing with missing data uses decision tree derivative models\n",
    "* Neural Networks can be used for imputation\n",
    "* Several strategies for integrating imputation into model building pipelines\n",
    "  * Imputer should be a processing step (important that models are saveable)\n",
    "  * Multiple Imputation can use data augmentation or multiple models\n",
    "  * Bagging can be applied to single imputation performed multiply\n",
    "  * Missingness (or imputed) can be added as a flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "authorship_tag": "ABX9TyPpLv6R3L0XkmwitYmu11KS",
   "collapsed_sections": [],
   "name": "Untitled5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
