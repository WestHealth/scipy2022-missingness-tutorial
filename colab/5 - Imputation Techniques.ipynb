{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGJmuVrOrepP"
      },
      "source": [
        "# $\\color{purple}{\\text{Understanding Missing Data and How to Deal with It (Part 5)}}$\n",
        "\n",
        "## $\\color{purple}{\\text{Advanced Imputation Techniques}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ]
      },
      "source": [
        "### $\\color{purple}{\\text{Colab Environmental Setup}}$"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "colab"
        ]
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/missingness_tutorial')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{Libraries for this lesson}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from helpers import stat_comparison, spotlight_donors, ImputationDisplayer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from autoimpute.imputations import SingleImputer\n",
        "from autoimpute.imputations import MultipleImputer\n",
        "from autoimpute.imputations import MiceImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "executionInfo": {
          "elapsed": 20431,
          "status": "ok",
          "timestamp": 1654721415225,
          "user": {
            "displayName": "Haw-minn Lu",
            "userId": "16109571175851064283"
          },
          "user_tz": 420
        },
        "id": "e7N2XN4NFG-d",
        "outputId": "6103427b-15a2-4d9f-9d57-579328cc0633"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/full_set.csv')\n",
        "mar_df = pd.read_csv('data/mar_set.csv')\n",
        "ImputationDisplayer(mar_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## $\\color{purple}{\\text{Multivariate Imputation}}$\n",
        "Conventional Multivariate Imputation falls into 2 categories\n",
        "* Regression Imputation\n",
        "* Hot Deck Imputation\n",
        "\n",
        "Another cutting edge method worth mentioning\n",
        "* Neural Network Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-lI2daBFGxl"
      },
      "source": [
        "## $\\color{purple}{\\text{Regression Imputation}}$\n",
        "\n",
        "General Technique:\n",
        "Use Regression/Classification Models to impute Numeric/Categorical Missing Values\n",
        "* Linear Regression\n",
        "* Stocastic Linear Regression\n",
        "* Logistic Regression\n",
        "* Other Possibilities (generally unexplored)\n",
        "  * Random Forest\n",
        "  * Decision Trees\n",
        "  * KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGTqexiQMgmM"
      },
      "source": [
        "### $\\color{purple}{\\text{Linear Regression}}$\n",
        "\n",
        "* Works with MAR\n",
        "* Can impute illegal (out of bounds) values\n",
        "* Can under estimate variance/covariance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSE9PBfSoF3c"
      },
      "outputs": [],
      "source": [
        "linear_regressor = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Perform the linear regresssion\n",
        "\n",
        "We base the prediction of `feature a` on the remaining features in `rest`. We only run the regression on data with full rows, `full_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rest = ['feature b', 'feature c', 'feature d', 'uncorrelated']\n",
        "full_data = mar_df.dropna()\n",
        "linear_regressor.fit(full_data[rest], full_data['feature a'])\n",
        "predicted = linear_regressor.predict(mar_df[rest])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### A note about a code pattern\n",
        "\n",
        "I will be repeating the following code pattern or variation thereof. \n",
        "\n",
        "```.assign(**{'feature a': df['feature a'].where(~df['feature a'].isnull(), predicted)``` \n",
        "\n",
        "Depending on the use case, I'll either be filling in a value when the value is missing or substituting a NaN where a missing value is (see section on MICE below).\n",
        "\n",
        "This basically substitutes the predicted value only when values are missing.\n",
        "\n",
        "This is basically the same pattern as\n",
        "\n",
        "```df['feature a'] = df['feature a'].where(~df['feature a'].isnull(), predicted)```\n",
        "\n",
        "but allows for passing the dataframe or method chaining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputed = mar_df.assign(\n",
        "    **{\n",
        "        'feature a':\n",
        "        mar_df['feature a'].where(~mar_df['feature a'].isnull(), predicted)\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{Analyze the Results}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stat_comparison(df, imputed, 'feature a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mar_df.displayer(imputed, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{Stochastic Regression}}$\n",
        "* Extends Linear Regression by adding noise modelling the residuals\n",
        "* Better simulates variance\n",
        "* Can also produce out of bounds values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We rely on the linear regression prediction above. And calculate the statistics behind the residuals of the linear regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "residual = mar_df['feature a'] - predicted\n",
        "residual.mean()\n",
        "residual.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the prediction we model the residual noise as a normal distribution and adjust predictions accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "residual_noise = np.random.normal(residual.mean(), residual.std(), 20000)\n",
        "predicted += residual_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputed = mar_df.assign(\n",
        "    **{\n",
        "        'feature a':\n",
        "        mar_df['feature a'].where(~mar_df['feature a'].isnull(), predicted)\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{Analyze the Results}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{Built into}}$ `autoimpute`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = SingleImputer('least squares')\n",
        "ls_imputations = imputer.fit_transform(mar_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from autoimpute.imputations import SingleImputer\n",
        "\n",
        "imputer = SingleImputer('stochastic')\n",
        "st_imputations = imputer.fit_transform(mar_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### $\\color{purple}{\\text{Analyze Results}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{Just For Fun}}$\n",
        "Let's use a Random Forest Regression instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_regressor = RandomForestRegressor()\n",
        "rest = ['feature b', 'feature c', 'feature d', 'uncorrelated']\n",
        "full_data = mar_df.dropna()\n",
        "rf_regressor.fit(full_data[rest], full_data['feature a'])\n",
        "predicted = rf_regressor.predict(mar_df[rest])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputed = mar_df.assign(\n",
        "    **{\n",
        "        'feature a':\n",
        "        mar_df['feature a'].where(~mar_df['feature a'].isnull(), predicted)\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### $\\color{purple}{\\text{Analyze Results}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D13nfWuLsk-u"
      },
      "source": [
        "\n",
        "## $\\color{purple}{\\text{Categorical Variables}}$\n",
        "\n",
        "Imputation of categorical variables employs classification in place of regression. Most common is multinomial logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_mar_df = pd.read_csv('data/categorical_mar.csv')\n",
        "ImputationDisplayer(cat_mar_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "rest = ['feature a', 'feature b', 'feature c']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "cleaned_df = cat_mar_df.dropna()\n",
        "lr = LogisticRegression(random_state=0,\n",
        "                        max_iter=1000).fit(cleaned_df[rest],\n",
        "                                           cleaned_df['cat feature'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "impute = lr.predict(cat_mar_df[rest])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputed = cat_mar_df.assign(\n",
        "    **{\n",
        "        'cat feature':\n",
        "        cat_mar_df['cat feature'].where(~cat_mar_df['cat feature'].isnull(),\n",
        "                                        impute)\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_mar_df.displayer(imputed, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA-u2Tz8sa-8"
      },
      "source": [
        "## $\\color{purple}{\\text{Hot Deck Imputation}}$\n",
        "* General idea is to randomly sample imputed values from remaining good values.\n",
        "* Doesn't impute out of bounds values\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "* For each missing value, a set of donors is selected from good values\n",
        "* A value is randomly selected from the set of donors\n",
        "* Donors are selected based on some metric based algorithm\n",
        "\n",
        "The `demo_mar.csv` dataset is the first 10 entries from one of my earlier runs. It has one missing value in `feature a`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "demo_df = pd.read_csv('data/demo_mar.csv')\n",
        "demo_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use Euclidean distance to demonstrate how Hot Deck Imputation works, but in practice the metric is usually more statistically based and complex. For simplicity we add a `distance` feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distance(x):\n",
        "    return np.linalg.norm((x - demo_df.iloc[7]).dropna())\n",
        "\n",
        "\n",
        "demo_df['distance'] = demo_df.apply(distance, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Donor Selection\n",
        "\n",
        "[Van Buuren](https://stefvanbuuren.name/fimd/) identifies 4 methods of selecting donors\n",
        "\n",
        "#### Method 1: (Single Donor)\n",
        "\n",
        "Pick the sample closest to the missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "donor = demo_df.dropna().nsmallest(1, 'distance')\n",
        "spotlight_donors(demo_df, donor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Method 2:\n",
        "\n",
        "Donors selected from all points under a fixed threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 2\n",
        "donors = demo_df.dropna()[demo_df.dropna().distance < threshold]['feature a']\n",
        "spotlight_donors(demo_df, donors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Method 3:\n",
        "\n",
        "Closest N points selected as the set of donors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 3\n",
        "donors = demo_df.nsmallest(N + 1, 'distance').tail(N)['feature a']\n",
        "spotlight_donors(demo_df, donors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Method 4:\n",
        "\n",
        "Donors are all points, but donor selected randomly based on the distance, closest having higher probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "# Pick with probability inversely proportionally to distance\n",
        "weights = 1 / demo_df.dropna()['distance']\n",
        "random.choices(demo_df.dropna()['feature a'].to_list(),\n",
        "               k=1,\n",
        "               weights=weights.to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA-u2Tz8sa-8"
      },
      "source": [
        "## $\\color{purple}{\\text{Predictive Mean Matching}}$\n",
        "Uses linear interpolation as part of the metric.\n",
        "\n",
        "Basically, the donors are selected from those observations whose predicted values from linear regression most closely matches that predicted from the missing value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linear_regressor = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "demo_df = pd.read_csv('data/demo_mar.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rest = ['feature b', 'feature c', 'feature d', 'uncorrelated']\n",
        "full_data = demo_df.dropna()\n",
        "linear_regressor.fit(full_data[rest], full_data['feature a'])\n",
        "demo_df['regression'] = linear_regressor.predict(demo_df[rest])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "demo_df['distance'] = np.abs(demo_df.regression - demo_df.regression.iloc[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 3\n",
        "donors = demo_df.dropna().sort_values('distance').iloc[0:N]['feature a']\n",
        "spotlight_donors(demo_df, donors, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predictive Mean Matching is the preferred imputation method, but can be computationally expensive, so for this demo the dataset is truncated to 100 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from autoimpute.imputations import SingleImputer\n",
        "\n",
        "demo_df = mar_df[0:100].copy()\n",
        "imputer = SingleImputer('pmm')\n",
        "imputations = imputer.fit_transform(demo_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mar_df.displayer(imputations, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p10VFs81Y21_"
      },
      "source": [
        "## $\\color{purple}{\\text{Advanced Imputation Techniques: Multivariate Imputation by Chained Equations (MICE)}}$\n",
        "* Often considered the gold standard of imputation\n",
        "* Is actually more of an imputation blueprint\n",
        "* Applicable with missingness in multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EY6qUH3oElL"
      },
      "outputs": [],
      "source": [
        "dmcar_df = pd.read_csv('data/double_mcar_set.csv')\n",
        "missing_df = pd.DataFrame({\n",
        "    'feature a': dmcar_df['feature a'].isnull(),\n",
        "    'feature b': dmcar_df['feature b'].isnull()\n",
        "})\n",
        "ImputationDisplayer(dmcar_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### First step: Impute each missing value with some form of univariate imputation (usually mean or median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "step1_df = dmcar_df.fillna({\n",
        "    'feature a': dmcar_df['feature a'].mean(),\n",
        "    'feature b': dmcar_df['feature b'].median()\n",
        "})\n",
        "dmcar_df.displayer(step1_df, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Second Step: For each column impute using a regression or hot deck technique\n",
        "Start with `feature a` then `feature b`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Clear the missing values for the imputer then impute feature a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = SingleImputer('least squares')\n",
        "step2a_df = imputer.fit_transform(\n",
        "    step1_df.assign(**{\n",
        "        'feature a':\n",
        "        step1_df['feature a'].where(~missing_df['feature a'], np.nan)\n",
        "    }))\n",
        "dmcar_df.displayer(step2a_df, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = SingleImputer('least squares')\n",
        "step2_df = imputer.fit_transform(\n",
        "    step2a_df.assign(\n",
        "        **{\n",
        "            'feature b':\n",
        "            step2a_df['feature b'].where(~missing_df['feature b'], np.nan)\n",
        "        }))\n",
        "dmcar_df.displayer(step2_df, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Repeat Step 2 until results converge sufficiently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = SingleImputer('least squares')\n",
        "step3a_df = imputer.fit_transform(\n",
        "    step2_df.assign(**{\n",
        "        'feature a':\n",
        "        step2_df['feature a'].where(~missing_df['feature a'], np.nan)\n",
        "    }))\n",
        "step3_df = imputer.fit_transform(\n",
        "    step3a_df.assign(\n",
        "        **{\n",
        "            'feature b':\n",
        "            step3a_df['feature b'].where(~missing_df['feature b'], np.nan)\n",
        "        }))\n",
        "dmcar_df.displayer(step3_df, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stat_comparison(df, step3_df, 'feature a')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "stat_comparison(df, step3_df, 'feature b')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{MICE imputer in}}$ `autoimpute`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = MiceImputer(n=1, k=5, strategy='least squares')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MICE imputer returns a multiple imputation (see next section) we unpack it by referencing [0][1]\n",
        "imputed = [each for each in imputer.fit_transform(dmcar_df)][0][1]\n",
        "dmcar_df.displayer(imputed, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DRKuaocr9ja"
      },
      "source": [
        "## $\\color{purple}{\\text{Advanced Imputation Techniques: Multiple Imputation}}$\n",
        "\n",
        "Many of the imputation techniques are stochastic in nature meaning that if you run the imputation a second time. You would a slightly different imputed values for the missing values.\n",
        "\n",
        "**Multiple Imputation** is the method which repeatedly imputes missing values. The result is a collection of possible imputed values.\n",
        "\n",
        "With a collection of imputed values for each missing value, you can perform statistics and carry through error margins and confidence intervals through your models. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MkREaCdmWXJ"
      },
      "source": [
        "We will use `autoimpute`'s multiple imputer to demonstrate, by default it produces 5 imputations. It returns this as a generator which we unpack using list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "executionInfo": {
          "elapsed": 336,
          "status": "error",
          "timestamp": 1653069148759,
          "user": {
            "displayName": "Haw-minn Lu",
            "userId": "16109571175851064283"
          },
          "user_tz": 420
        },
        "id": "o_H45smZmIfg",
        "outputId": "234074cd-b732-4689-84c8-f1c206c980ff"
      },
      "outputs": [],
      "source": [
        "imputer = MultipleImputer(strategy='least squares')\n",
        "imputations = imputer.fit_transform(mar_df)\n",
        "lists = list(imputations)  # Unscramble the generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The return value is an array of tuples. Each tuple is a pair with the imputation index (ordinal count) and the imputed dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRwJZtc7mVjK",
        "tags": [
          "master"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the second full imputation\n",
        "mar_df.displayer(lists[2][1], 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\color{red}{\\Large{\\text{ \u26a0}}}$ the `least squares` is option is deterministic. You will notice all the imputations are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[each[1].iloc[1]['feature a'] for each in lists]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we use the `stochastic` strategy each missing value will have multiple imputed values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = MultipleImputer(strategy='stochastic')\n",
        "imputations = imputer.fit_transform(mar_df)\n",
        "lists = list(imputations)  # Unscramble the generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[each[1].iloc[1]['feature a'] for each in lists]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{Conclusion}}$\n",
        "\n",
        "* Univariate Imputation is fast and easy but works only on MCAR\n",
        "* Multivariate Imputation comes in two broad flavors\n",
        "  * Regression/Classification\n",
        "  * Hot Deck Imputation\n",
        "* Multivariate Imputation with Chained Equations (MICE) deals well with multiple missing features\n",
        "* Multiple Imputation can be used to carry statistics into your model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $\\color{purple}{\\text{References}}$\n",
        "* van Buuren, S., Groothuis-Oudshoorn, K.: mice: Multivariate imputation by\n",
        "chained equations in r. _Journal of Statistical Software_, Articles 45(3), 1\u201367 (2011).\n",
        "https://doi.org/10.18637/jss.v045.i03, https://www.jstatsoft.org/v045/i03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOzI6saudMRGj5Q9rKp9Mrq",
      "collapsed_sections": [],
      "name": "4 - Imputation Techniques.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}